<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE help [
<!ENTITY lt "#38;#60;">
<!ENTITY gt "&#62;">
<!ENTITY amp "&#38;#38;">
<!ELEMENT help (name , synopsis , description* , arguments+ , outputs* , example* , bugs* , references* , reporting* , see-also*)*>
<!ELEMENT name (#PCDATA)>
<!ELEMENT synopsis (#PCDATA)>
<!ELEMENT description (#PCDATA)>
<!ELEMENT arguments (positional* , required-flagged* , optional-flagged*)*>
<!ELEMENT positional (intro* , argument* , explanation*)*>
<!ELEMENT required-flagged (intro* , argument* , explanation*)*>
<!ELEMENT optional-flagged (intro* , argument* , explanation*)*>
<!ELEMENT intro (#PCDATA)>
<!ELEMENT argument (#PCDATA)>
<!ELEMENT explanation (#PCDATA)>
<!ELEMENT outputs (output* , explanation*)>
<!ELEMENT output (#PCDATA)>
<!ELEMENT example (#PCDATA)>
<!ELEMENT bugs (#PCDATA)>
<!ELEMENT references (#PCDATA)>
<!ELEMENT reporting (#PCDATA)>
<!ELEMENT see-also (#PCDATA)>
]>

<help>
  <name>mri_robust_register</name>
  <synopsis>mri_robust_register --mov &lt;mov.mgz&gt; --dst &lt;dst.mgz&gt; --lta &lt;reg.lta&gt; [options]</synopsis>
  <description>This program computes an inverse consistent registration of two volumes (within modality, 6-7 DOF). It is robust with respect to outlier voxel or longitudinal change.
  This program symmetrically aligns two volumes. It uses a method based on robust statistics to detect outliers and removes them from the registration. This leads to highly accurate registrations even with local changes in the image (e.g. jaw movement). The main purpose is to find the rigid registration (translation, rotation) of longitudinal data, but the method can be used to rigidly align different images. An additional optional intensity scale parameter can be used to adjust for global intensity differences. The extension to affine registration is being tested.
  
If the registration fails: 
The registration can fail because of several reasons, most likely due to large intensity differences or non-linear differences in the image. You can try:
 * Switch on intensity scaling (--iscale).
 * If you specified a manual saturation (--sat) too many voxels might be considered outlier early in the process. You can check this by outputing the weights (--weights ow.mgz) and by looking at them in:
   tkmedit -f dst.mgz -aux mov.mgz -overlay ow.mgz 
If most of the brain is labeled outlier, try to set the saturation to a higher value (eg. --sat 12) or use --satit to automatically determine a good sat value.
 * If you used automatic saturation estimation (--satit), try to specify the sensitivity manually or adjust --wlimit (which is around 0.16 by default). A lower wlimit should reduce the number of outlier voxels.  </description>
  <arguments>
    <positional>
      <intro>None.</intro>
    </positional>
    <required-flagged>
      <argument>--mov &lt;mov.mgz&gt;</argument>
      <explanation>input movable volume to be aligned to target</explanation>
      <argument>--dst &lt;dst.mgz&gt;</argument>
      <explanation>input target volume</explanation>
      <argument>--lta &lt;reg.lta&gt;</argument>
      <explanation>output registration (transform from mov to dst)</explanation>
      <intro>One of the following is required for sensitivity when using ROB (robust cost function, default):</intro>
      <argument>--sat &lt;real&gt;</argument>
      <explanation>set outlier sensitivity manually (e.g. '--sat 4.685' ). Higher values mean less sensitivity. Check --weights to see how much outliers get detected and adjust this parameter manually.</explanation>
      <argument>--satit</argument>
      <explanation>auto-detect good sensitivity (works only for head or full brain images). Manually specify sat for other types of input!</explanation>
    </required-flagged>
    <optional-flagged>
      <argument>--mapmov &lt;aligned.mgz&gt; </argument>
      <explanation>output image: movable mapped and resampled at destination</explanation>
      <argument>--mapmovhdr &lt;aligned.mgz&gt; </argument>
      <explanation>output image: movable aligned to destination (no resampling, only adjusting header vox2ras)</explanation>
      <argument>--weights &lt;weights.mgz&gt; </argument>
      <explanation>output weights (outliers) map in destination space (1=outlier)</explanation>
      <argument>--oneminusw</argument>
      <explanation>weights (outlier) map will be inverted (0=outlier), as in earlier versions</explanation>
      <argument>--iscale </argument>
      <explanation>estimate intensity scale factor (default no).
Highly recommended for unnormalized images!</explanation>
      <argument>--iscaleout &lt;fname.txt&gt;</argument>
      <explanation>output text file for iscale value (will activate --iscale). Default: no iscale output</explanation>
      <argument>--iscalein &lt;fname.txt&gt;</argument>
      <explanation>initial input text file for iscale value (probably you want to also activate --iscale to estimate final value?)</explanation>
      <argument>--transonly</argument>
      <explanation>find 3 parameter translation only</explanation>
      <argument>--affine</argument>
      <explanation>find 12 parameter affine transform</explanation>
      <argument>--ixform lta</argument>
      <explanation>use initial transform lta on source. Default: align centers of mass (see also --noinit). The final output transform will be from source to target and thus include the ixform.</explanation>
      <argument>--initorient</argument>
      <explanation>use moments for orientation initialization (default false). Recommended for stripped brains, but not with full head images with different cropping. </explanation>
      <argument>--noinit</argument>
      <explanation>skip automatic transform initialization.
Default: translate images to align centers of mass, good for within subject full head or brain images.
Use --noinit if center of mass is meaningless, e.g. when registering different resolutions or parts to larger images. </explanation>
      <argument>--vox2vox</argument>
      <explanation>output VOX2VOX lta file (default is RAS2RAS)</explanation>
      <argument>--cost &lt;str&gt;</argument>
      <explanation>Cost function:
      ROB (robust) &lt;- default,
      MI  (mutual information),
      NMI (normalized mutual information),
      ECC (entropy correlation coefficient) experimental,
      NCC (normalized cross corrrelation) experimental,
      SCR (symetrized correlation ratio) experimental.
Use MI, NMI (recommended), ECC, NCC or SCR for registering cross modality.</explanation>

      <argument>--nosym</argument>
      <explanation>do not map to half way space, but resample mov to dst internally (destroys symmetry, but is useful when registering a larger block to a part)</explanation>
      <argument>--maxit &lt;#&gt;</argument>
      <explanation>iterate max # times on each resolution (default 5)</explanation>
      <argument>--highit &lt;#&gt;</argument>
      <explanation>iterate max # times on highest resolution (default 5)</explanation>
      <argument>--epsit &lt;real&gt;</argument>
      <explanation>stop iterations when transform update falls below &lt;real&gt; RMS distance (default 0.01)</explanation>
      <argument>--nomulti</argument>
      <explanation>process highest resolution only (no multiscale)</explanation>
      <argument>--maxsize &lt;#&gt;</argument>
      <explanation>specify largest dimension for gaussian pyramid (will not process resolutions higher than #). Default: process up to the input resolution. You can use this to prevent the algorithm to run on the high resolutions (to avoid long runtimes and memory issues)</explanation>
      <argument>--minsize &lt;#&gt;</argument>
      <explanation>specify smallest dimension for gaussian pyramid (will not downsample resolutions smaller than #). Default: smallest dimension 16</explanation>      
      <argument>--wlimit &lt;real&gt;</argument>
      <explanation>sets maximal outlier limit for --satit (default 0.16), reduce to decrease outlier sensitivity </explanation>
      <argument>--subsample &lt;real&gt;</argument>
      <explanation>subsample if dim &gt; # on all axes (default no subsampling)</explanation>
      <argument>--floattype</argument>
      <explanation>convert images to float internally (default: keep input type)</explanation> 
            
      <argument>--maskmov &lt;mask.mgz&gt;</argument>
      <explanation>mask mov image with mask.mgz</explanation>
      <argument>--maskdst &lt;mask.mgz&gt;</argument>
      <explanation>mask dst image with mask.mgz</explanation>
      <argument>--halfmov &lt;hm.mgz&gt;</argument>
      <explanation>outputs half-way mov (resampled in halfway space)</explanation>
      <argument>--halfdst &lt;hd.mgz&gt;</argument>
      <explanation>outputs half-way dst (resampled in halfway space)</explanation>
      <argument>--halfweights hw.mgz</argument>
      <explanation>outputs half-way weights (resampled in halfway space)</explanation>
      <argument>--halfmovlta hm.lta</argument>
      <explanation>outputs transform from mov to half-way space</explanation>
      <argument>--halfdstlta hd.lta</argument>
      <explanation>outputs transform from dst to half-way space</explanation>

      <argument>--debug</argument>
      <explanation>show debug output (default no debug output)</explanation>
      <argument>--verbose</argument>
      <explanation>0 quiet, 1 normal (default), 2 detail</explanation>
      
    </optional-flagged>
  </arguments>
  <example>Simple Full Head Registration:
  
mri_robust_register --mov vol1.mgz --dst vol2.mgz --lta v1to2.lta --mapmov v1to2.mgz --weights v1to2-weights.mgz --iscale --satit

Computes the symmetric rigid registration (translation and rotation) of vol1.mgz to vol2.mgz using robust statistics and with an additional global intensity scaling parameter. The output is the transform (v1to2.lta) and image v1to2.mgz (the vol1.mgz resampled to the target image). Additionally the weights of the robust registation (outlier detection) are saved. Everything can be viewed with:

freeview vol2.mgz v1to2.mgz v1to2-weights.mgz:colormap=heat </example>
  <example>Half Way Space Output:
  
mri_robust_register --mov vol1.nii --dst vol2.nii --lta v1to2.lta --halfmov h1.nii --halfdst h2.nii --halfmovlta h1.lta --halfdstlta h2.lta --iscale --satit
  
Computes the rigid robust registration with intensity scaling of Nifti vol1 to vol2 (the registration will be saved in v1to2.lta). Additionally outputs the half-way volumes h1.nii and h2.nii (with corresponding transforms h1.lta and h2.lta). As both volumes are mapped to the half-way space, they will both be resampled. This can be used to construct an unbiased mean volume (e.g. with mri_average) or to compute change maps. The output can be viewed with: 

freeview h1.nii h2.nii</example>
  <example>Part to Full Registration:
  
mri_robust_register --mov fullhemi.mgz --dst part.mgz --noinit --nosym --sat 8 --maxsize 380 --mapmovhdr hemi2part.mgz --lta hemi2part.lta
  
Registers a full hemisphere with a high-resolutional part (e.g. hippocampal slices). It is recommended to specify the part as the target (the full hemi image will then be cropped internally). For partial registration to work we need to skip the center of mass initialization (--noinit) and switch off the half way space (--nosym). Also the inputs need to be in an approximate alignment, alternatively you can pass --ixform with a transform that approximately aligns the images. The satuarion needs to be specified manually with --sat. You can output the weights with --weights to see if too many voxels are removed and increase the value (to reduce outlier sensitivity). For high-res inputs we limit the resolution to 380 to reduce run time and mem usage. The output will be the transform (--lta) and the mov mapped to dst w/o resampling (--mapmovhdr), only adjusting the header information. Look at results with:

freeview -v part.mgz part2hemi.mgz

You can also invert transforms and apply them :

mri_concatenate_lta -invert1 hemi2part.lta identity.nofile part2hemi.lta

mri_convert -at inv1.lta part.mgz part2hemi.mgz </example>
  <references>
Highly Accurate Inverse Consistent Registration: A Robust Approach, M. Reuter, H.D. Rosas, B. Fischl.  NeuroImage 53(4):1181-1196, 2010.
  http://dx.doi.org/10.1016/j.neuroimage.2010.07.020
  http://reuter.mit.edu/papers/reuter-robreg10.pdf 

Within-Subject Template Estimation for Unbiased Longitudinal Image Analysis. M. Reuter, N.J. Schmansky, H.D. Rosas, B. Fischl. NeuroImage 61(4):1402-1418, 2012.
  http://dx.doi.org/10.1016/j.neuroimage.2012.02.084
  http://reuter.mit.edu/papers/reuter-long12.pdf
  
  </references>
  <reporting>Report bugs to &lt;freesurfer@nmr.mgh.harvard.edu&gt;</reporting>
  <see-also>mri_robust_template (to simultaneously register 2 or more inputs to an unbiased mid space, e.g. to create within subject cross time template image)</see-also>
</help>
